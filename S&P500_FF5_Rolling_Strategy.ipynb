{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e090aa6d",
   "metadata": {},
   "source": [
    "# Factor-Based Stock Selection vs the S&P 500 (FF5 Rolling Strategy + ML Ranking)\n",
    "\n",
    "## Notebook flow (baseline + two-model comparison)\n",
    "\n",
    "This notebook contains:\n",
    "\n",
    "1. **A transparent baseline strategy** using rolling FF5 betas to form a monthly top‑50 portfolio.\n",
    "2. A **two-model machine learning comparison** (the part you “tried two models and chose one”):\n",
    "   - **Model 1:** Linear model (Logistic Regression)\n",
    "   - **Model 2:** XGBoost learning-to-rank\n",
    "\n",
    "Both ML models are trained and evaluated walk-forward (no look-ahead), and the final section compares the two models against **SPY**.\n",
    "\n",
    "### Sections\n",
    "\n",
    "1. **Setup** (imports + helper functions)\n",
    "2. **Data preparation**\n",
    "   - FF5 daily → monthly (compounded)\n",
    "   - Load S&P 500 monthly returns\n",
    "   - Merge + excess returns\n",
    "3. **Baseline factor strategy** (rolling FF5 betas → signal → top‑50 portfolio)\n",
    "4. **Backtest & benchmarking** (baseline vs SPY)\n",
    "5. **Two-model ML comparison** (Linear vs XGBoost)\n",
    "6. **Final conclusion** (choose the better-performing model)\n",
    "\n",
    "Run the notebook top-to-bottom (Kernel: Restart & Run All) to reproduce results and regenerate figures in `docs/assets/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8ee47",
   "metadata": {},
   "source": [
    "### 1. Import Libraries\n",
    "\n",
    "We import the core Python libraries needed for this project:\n",
    "- **pandas** for data loading and cleaning  \n",
    "- **numpy** for numerical regression  \n",
    "- **matplotlib** for visualization  \n",
    "- set the global plotting style for consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f702779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "# Ensure docs assets folder exists for GitHub Pages figures\n",
    "os.makedirs(\"docs/assets\", exist_ok=True)\n",
    "\n",
    "# XGBoost (Model 2 learning-to-rank)\n",
    "try:\n",
    "    from xgboost import XGBRanker\n",
    "    _HAS_XGBOOST = True\n",
    "except Exception:\n",
    "    XGBRanker = None\n",
    "    _HAS_XGBOOST = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96db42d5",
   "metadata": {},
   "source": [
    "## Part 0. Setup Helpers\n",
    "\n",
    "This section defines the small helper functions used throughout the notebook (OLS and rolling FF5 regression). Defining them up front makes the execution flow easier to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7596413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_numpy(X, y):\n",
    "    \"\"\"Perform closed-form OLS regression.\"\"\"\n",
    "    beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    return beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd164e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_factor_loadings(df, ticker, window=36, min_obs=24):\n",
    "    betas = []\n",
    "    dates = []\n",
    "\n",
    "    y_all = df[ticker].astype(float).values\n",
    "    X_all = df[[\"Mkt-RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\"]].astype(float).values\n",
    "    X_all = np.column_stack([np.ones(len(X_all)), X_all])\n",
    "\n",
    "    for i in range(window, len(df)):\n",
    "        y = y_all[i - window:i]\n",
    "        X = X_all[i - window:i]\n",
    "\n",
    "        mask = np.isfinite(y) & np.all(np.isfinite(X), axis=1)\n",
    "        if mask.sum() < min_obs:\n",
    "            continue\n",
    "\n",
    "        beta = ols_numpy(X[mask], y[mask])\n",
    "        betas.append(beta)\n",
    "        dates.append(df[\"date\"].iloc[i])\n",
    "\n",
    "    if len(betas) == 0:\n",
    "        return pd.DataFrame(columns=[\"alpha\", \"MKT\", \"SMB\", \"HML\", \"RMW\", \"CMA\"])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        betas,\n",
    "        index=dates,\n",
    "        columns=[\"alpha\", \"MKT\", \"SMB\", \"HML\", \"RMW\", \"CMA\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9116a633",
   "metadata": {},
   "source": [
    "## Part I. Baseline Strategy (Rolling FF5 Betas → Signal → Top-50 Portfolio)\n",
    "\n",
    "This part builds a transparent walk-forward factor strategy:\n",
    "- Estimate rolling 36-month FF5 betas per stock (on excess returns)\n",
    "- Forecast factor returns using a lagged trailing mean (no look-ahead)\n",
    "- Rank stocks each month by predicted return signal\n",
    "- Form a long-only equal-weight top-50 portfolio and compare vs SPY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1053e9b2",
   "metadata": {},
   "source": [
    "### 2. Load and Prepare Fama–French 5-Factor Data\n",
    "\n",
    "The FF5 dataset is provided in **daily format**, so we first:\n",
    "1. Load the raw daily CSV\n",
    "2. Remove footer text rows\n",
    "3. Convert the date to a proper `datetime`\n",
    "4. Forward-fill missing values\n",
    "5. Convert from **daily → monthly** by **compounding within each month**\n",
    "6. Convert the monthly dates to **month-start** to align with our market data\n",
    "\n",
    "This ensures both datasets use the *same monthly timestamps* and that the monthly factors represent monthly returns (not a single end-of-month observation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffcc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = pd.read_csv(\"data/raw/ff5_data.csv\")\n",
    "ff = ff[ff[\"Date\"].astype(str).str.isdigit()].copy()\n",
    "ff[\"date\"] = pd.to_datetime(ff[\"Date\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "ff = ff.dropna(subset=[\"date\"]).drop(columns=[\"Date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "factor_cols = [\"Mkt-RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\", \"RF\"]\n",
    "ff[factor_cols] = ff[factor_cols].ffill()\n",
    "ff[factor_cols] = ff[factor_cols] / 100.0\n",
    "\n",
    "ff = ff.set_index(\"date\")[factor_cols].sort_index()\n",
    "\n",
    "# Monthly RF by compounding daily RF\n",
    "rf_monthly = (1 + ff[\"RF\"]).resample(\"M\").prod() - 1\n",
    "\n",
    "# Monthly Mkt-RF computed from compounded market total return minus compounded RF\n",
    "mkt_total_daily = ff[\"Mkt-RF\"] + ff[\"RF\"]\n",
    "mkt_total_monthly = (1 + mkt_total_daily).resample(\"M\").prod() - 1\n",
    "mkt_rf_monthly = mkt_total_monthly - rf_monthly\n",
    "\n",
    "# Style factors compounded within the month\n",
    "other_factors = [\"SMB\", \"HML\", \"RMW\", \"CMA\"]\n",
    "other_monthly = (1 + ff[other_factors]).resample(\"M\").prod() - 1\n",
    "\n",
    "ff_monthly = pd.concat(\n",
    "    [mkt_rf_monthly.rename(\"Mkt-RF\"), other_monthly, rf_monthly.rename(\"RF\")],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Align to month-start timestamps (matches market data index)\n",
    "ff_monthly.index = ff_monthly.index.to_period(\"M\").to_timestamp()\n",
    "ff_monthly = ff_monthly.reset_index().rename(columns={\"date\": \"date\"})\n",
    "\n",
    "ff_monthly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb60a5ea",
   "metadata": {},
   "source": [
    "### 3. Load Market Return Data (Monthly)\n",
    "\n",
    "We load the pre-cleaned **monthly return matrix** of S&P 500 constituents.\n",
    "The dataset is already in wide format (`ticker columns`), and dates are already the **first day of each month**, so minimal cleaning is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ad407",
   "metadata": {},
   "outputs": [],
   "source": [
    "market = pd.read_csv(\"data/raw/market_data.csv\", parse_dates=[\"Date\"])\n",
    "market = market.rename(columns={\"Date\": \"date\"})\n",
    "market = market.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "market.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1a6c0",
   "metadata": {},
   "source": [
    "### 4. Merge Market Returns with Factor Data\n",
    "\n",
    "We merge the monthly market returns with the aligned monthly FF5 factors.\n",
    "The merge occurs cleanly after aligning FF5 month-end dates to month-start.\n",
    "\n",
    "We also fix column naming issues (e.g., `RF_y`) that arise from merging datasets with overlapping column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = market.merge(ff_monthly, on=\"date\", how=\"inner\")\n",
    "\n",
    "if \"RF_y\" in df.columns:\n",
    "    df = df.rename(columns={\"RF_y\": \"RF\"})\n",
    "if \"RF_x\" in df.columns:\n",
    "    df = df.drop(columns=[\"RF_x\"])\n",
    "\n",
    "factor_cols = [\"Mkt-RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\", \"RF\"]\n",
    "tickers = [c for c in df.columns if c not in [\"date\"] + factor_cols]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01341316",
   "metadata": {},
   "source": [
    "### 5. Compute Excess Returns for Each Stock\n",
    "\n",
    "To prepare the regression inputs, we convert raw stock returns into **excess returns**:\n",
    "\n",
    "\\[\n",
    "R_{i,t}^{excess} = R_{i,t} - RF_t\n",
    "\\]\n",
    "\n",
    "This is standard in multi-factor regression based on FF5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df.copy()\n",
    "\n",
    "df_excess = df.copy()\n",
    "df_excess[tickers] = df_excess[tickers].sub(df_excess[\"RF\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727e557",
   "metadata": {},
   "source": [
    "### 6. Ordinary Least Squares (OLS) via NumPy\n",
    "\n",
    "The helper function `ols_numpy(...)` is defined in **Part 0**. It uses `np.linalg.lstsq` to compute OLS coefficients for the rolling regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea145be",
   "metadata": {},
   "source": [
    "### 7. Rolling-Window Factor Regression\n",
    "\n",
    "The helper function `rolling_factor_loadings(...)` is defined in **Part 0**. For each stock, it fits a 36-month rolling regression of excess returns on the FF5 factors and stores the estimated betas over time.\n",
    "\n",
    "\\[\n",
    "R^{excess}_{i,t} = \\alpha_i + \\beta_{i}^T F_t + \\epsilon_t\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9479118",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b777d4a8",
   "metadata": {},
   "source": [
    "### 8. Run Rolling-Window Regressions Across All S&P 500 Tickers\n",
    "\n",
    "We apply the rolling regression to every ticker in the dataset.\n",
    "Some tickers may be skipped due to insufficient return history (e.g., IPOs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be257d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_dict = {}\n",
    "\n",
    "for t in tickers:\n",
    "    print(\"Running:\", t)\n",
    "    try:\n",
    "        beta_dict[t] = rolling_factor_loadings(df_excess, t)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {t}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b145b",
   "metadata": {},
   "source": [
    "### 9. Predict Returns Using Rolling Betas (Signal Generation)\n",
    "\n",
    "We generate a monthly expected return signal by combining each stock’s rolling factor exposures (betas) with a forecast of factor returns.\n",
    "\n",
    "Key design choices to improve robustness:\n",
    "- **No look-ahead**: factor forecasts are lagged by 1 month, so the signal at month \\(t\\) uses information available through \\(t-1\\).\n",
    "- **No intercept (alpha) in the signal**: we exclude regression intercepts from the prediction to reduce overfitting risk.\n",
    "\n",
    "This produces a cross-sectional expected return signal for each stock that we rank each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e505342",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_hist = df.set_index(\"date\")[[\"Mkt-RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\"]]\n",
    "\n",
    "# Forecast factors using only information available before month t (avoid look-ahead)\n",
    "factor_forecast = factor_hist.rolling(window=36, min_periods=24).mean().shift(1)\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for t in tickers:\n",
    "    betas = beta_dict.get(t)\n",
    "    if betas is None or betas.empty:\n",
    "        continue\n",
    "\n",
    "    idx = betas.index.intersection(factor_forecast.index)\n",
    "    if len(idx) == 0:\n",
    "        continue\n",
    "\n",
    "    # Use factor exposures only (exclude intercept/alpha to reduce overfitting risk)\n",
    "    beta_factors = betas.loc[idx, [\"MKT\", \"SMB\", \"HML\", \"RMW\", \"CMA\"]].values\n",
    "    f_mat = factor_forecast.loc[idx, [\"Mkt-RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\"]].values\n",
    "\n",
    "    pred = (beta_factors * f_mat).sum(axis=1)\n",
    "    predictions[t] = pd.Series(pred, index=idx)\n",
    "\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d384fc",
   "metadata": {},
   "source": [
    "### 10. Long-Only Portfolio Construction (Top 50 Stocks)\n",
    "\n",
    "Each month:\n",
    "- Sort predicted returns\n",
    "- Select the **top 50 stocks**\n",
    "- Assign equal weights (1/50 each)\n",
    "\n",
    "This produces a simple, transparent long-only factor strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b35cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_long_only_portfolio(pred_df, k=50):\n",
    "    weights = pd.DataFrame(0.0, index=pred_df.index, columns=pred_df.columns)\n",
    "\n",
    "    for dt, row in pred_df.iterrows():\n",
    "        row = row.dropna()\n",
    "        if row.empty:\n",
    "            continue\n",
    "\n",
    "        top_k = row.nlargest(min(k, len(row))).index\n",
    "        w = 1.0 / len(top_k)\n",
    "        weights.loc[dt, top_k] = w\n",
    "\n",
    "    return weights\n",
    "\n",
    "weights = build_long_only_portfolio(pred_df)\n",
    "weights.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70f822",
   "metadata": {},
   "source": [
    "## Part II. Backtest & Benchmarking (Strategy vs SPY)\n",
    "\n",
    "### 11. Realized Monthly Portfolio Returns\n",
    "\n",
    "We evaluate performance by applying the portfolio weights formed at month \\(t\\) to the realized stock returns for month \\(t\\).\n",
    "\n",
    "Because the expected return signal at month \\(t\\) is constructed using only information available up to \\(t-1\\) (rolling betas and a lagged factor forecast), this is an out-of-sample evaluation at a monthly frequency.\n",
    "\n",
    "\\[\n",
    "R^{portfolio}_t = \\sum_i w_{i,t} R_{i,t}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realized (same-month) total returns for each stock\n",
    "realized_returns = df_total.set_index(\"date\")[tickers]\n",
    "\n",
    "common_index = weights.index.intersection(realized_returns.index)\n",
    "weights_aligned = weights.loc[common_index]\n",
    "realized_aligned = realized_returns.loc[common_index]\n",
    "\n",
    "available = realized_aligned.notna()\n",
    "w_eff = weights_aligned.where(available, 0.0)\n",
    "denom = w_eff.sum(axis=1).replace(0.0, np.nan)\n",
    "\n",
    "# Effective portfolio weights actually used after dropping missing returns\n",
    "weights_used = w_eff.div(denom, axis=0)\n",
    "\n",
    "portfolio_returns = (w_eff * realized_aligned.fillna(0.0)).sum(axis=1) / denom\n",
    "active = denom.notna()\n",
    "\n",
    "portfolio_returns = portfolio_returns.loc[active]\n",
    "weights_aligned = weights_aligned.loc[active]\n",
    "weights_used = weights_used.loc[active]\n",
    "\n",
    "portfolio_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0c0cc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d669682",
   "metadata": {},
   "source": [
    "### 12. Load SPY Benchmark Returns\n",
    "\n",
    "We load monthly SPY returns to benchmark our strategy.\n",
    "The benchmark is aligned to the same monthly timestamps as the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = pd.read_csv(\"data/raw/spy_monthly_returns.csv\", parse_dates=[\"Date\"])\n",
    "benchmark = benchmark.rename(columns={\"Date\": \"date\", \"SPY\": \"return\"})\n",
    "benchmark = benchmark.set_index(\"date\")[\"return\"]\n",
    "\n",
    "benchmark_ret = benchmark.reindex(portfolio_returns.index)\n",
    "benchmark_ret.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe991c",
   "metadata": {},
   "source": [
    "### 13. Performance Evaluation: Sharpe Ratio & Cumulative Returns\n",
    "\n",
    "We compute:\n",
    "- Annualized Sharpe Ratio (computed on **excess returns**)\n",
    "- Cumulative returns of both the strategy and the SPY benchmark\n",
    "- A comparison plot\n",
    "\n",
    "The Sharpe ratio measures **risk-adjusted return**:\n",
    "\n",
    "\\[\n",
    "Sharpe = \\frac{E[R^{excess}]}{\\sigma(R^{excess})} \\times \\sqrt{12}\n",
    "\\]\n",
    "\n",
    "A higher Sharpe indicates better risk-adjusted performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d667ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(r):\n",
    "    r = pd.Series(r).dropna()\n",
    "    if r.std() == 0 or len(r) == 0:\n",
    "        return np.nan\n",
    "    return (r.mean() / r.std()) * np.sqrt(12)\n",
    "\n",
    "def annualized_vol(r):\n",
    "    r = pd.Series(r).dropna()\n",
    "    if len(r) == 0:\n",
    "        return np.nan\n",
    "    return r.std() * np.sqrt(12)\n",
    "\n",
    "def cagr(r):\n",
    "    r = pd.Series(r).dropna()\n",
    "    if len(r) == 0:\n",
    "        return np.nan\n",
    "    growth = (1 + r).prod()\n",
    "    years = len(r) / 12\n",
    "    if years <= 0:\n",
    "        return np.nan\n",
    "    return growth ** (1 / years) - 1\n",
    "\n",
    "def max_drawdown(cum_curve):\n",
    "    cum_curve = pd.Series(cum_curve).dropna()\n",
    "    if len(cum_curve) == 0:\n",
    "        return np.nan\n",
    "    running_max = cum_curve.cummax()\n",
    "    dd = cum_curve / running_max - 1\n",
    "    return dd.min()\n",
    "\n",
    "# ---- Portfolio diagnostics ----\n",
    "holdings_count = (weights_used > 0).sum(axis=1)\n",
    "turnover = 0.5 * weights_used.diff().abs().sum(axis=1).fillna(0.0)\n",
    "\n",
    "# Transaction costs are DISABLED by default for this project.\n",
    "# If you want to enable them later, set cost_bps to a positive value (e.g., 10 or 25).\n",
    "cost_bps = 0\n",
    "cost_rate = cost_bps / 10000.0\n",
    "portfolio_returns_net = portfolio_returns - cost_rate * turnover\n",
    "\n",
    "# Align RF to portfolio dates for Sharpe and excess-return metrics\n",
    "rf_series = df_total.set_index(\"date\")[\"RF\"].reindex(portfolio_returns.index)\n",
    "\n",
    "portfolio_excess = portfolio_returns - rf_series\n",
    "portfolio_excess_net = portfolio_returns_net - rf_series\n",
    "benchmark_excess = benchmark_ret - rf_series\n",
    "\n",
    "# Active return (strategy vs SPY)\n",
    "active_gross = portfolio_returns - benchmark_ret\n",
    "active_net = portfolio_returns_net - benchmark_ret\n",
    "\n",
    "# ---- Equity curves ----\n",
    "cum_port_gross = (1 + portfolio_returns).cumprod()\n",
    "cum_port_net = (1 + portfolio_returns_net).cumprod()\n",
    "cum_bench = (1 + benchmark_ret.fillna(0.0)).cumprod()\n",
    "\n",
    "# ---- Drawdowns ----\n",
    "dd_port_gross = cum_port_gross / cum_port_gross.cummax() - 1\n",
    "dd_port_net = cum_port_net / cum_port_net.cummax() - 1\n",
    "dd_bench = cum_bench / cum_bench.cummax() - 1\n",
    "\n",
    "# ---- Summary metrics ----\n",
    "print(\"Backtest window:\")\n",
    "print(f\"  Start: {portfolio_returns.index.min().date()}\")\n",
    "print(f\"  End:   {portfolio_returns.index.max().date()}\")\n",
    "print(f\"  Months: {len(portfolio_returns)}\")\n",
    "\n",
    "print(\"\\nHoldings diagnostics:\")\n",
    "print(f\"  Avg holdings/month: {holdings_count.mean():.1f}\")\n",
    "print(f\"  Min holdings/month: {holdings_count.min()}\")\n",
    "print(f\"  Max holdings/month: {holdings_count.max()}\")\n",
    "\n",
    "print(\"\\nTurnover diagnostics:\")\n",
    "print(f\"  Avg monthly turnover: {turnover.mean():.3f}\")\n",
    "print(f\"  Median monthly turnover: {turnover.median():.3f}\")\n",
    "print(f\"  90th pct turnover: {turnover.quantile(0.90):.3f}\")\n",
    "\n",
    "print(\"\\nPerformance (Excess-return metrics for Sharpe):\")\n",
    "print(\"  Strategy Sharpe (Excess):\", sharpe_ratio(portfolio_excess))\n",
    "print(\"  Benchmark (SPY) Sharpe (Excess):\", sharpe_ratio(benchmark_excess))\n",
    "\n",
    "print(\"\\nPerformance (Total-return metrics):\")\n",
    "print(\"  Strategy CAGR:\", cagr(portfolio_returns))\n",
    "print(\"  SPY CAGR:\", cagr(benchmark_ret))\n",
    "\n",
    "print(\"  Strategy Vol (ann.):\", annualized_vol(portfolio_returns))\n",
    "print(\"  SPY Vol (ann.):\", annualized_vol(benchmark_ret))\n",
    "\n",
    "mdd_gross = max_drawdown(cum_port_gross)\n",
    "mdd_bench = max_drawdown(cum_bench)\n",
    "\n",
    "print(\"  Strategy Max Drawdown:\", mdd_gross)\n",
    "print(\"  SPY Max Drawdown:\", mdd_bench)\n",
    "\n",
    "calmar_gross = cagr(portfolio_returns) / abs(mdd_gross) if pd.notna(mdd_gross) and mdd_gross != 0 else np.nan\n",
    "calmar_bench = cagr(benchmark_ret) / abs(mdd_bench) if pd.notna(mdd_bench) and mdd_bench != 0 else np.nan\n",
    "\n",
    "print(\"  Strategy Calmar:\", calmar_gross)\n",
    "print(\"  SPY Calmar:\", calmar_bench)\n",
    "\n",
    "print(\"\\nRelative to SPY (Information Ratio on active returns):\")\n",
    "print(\"  Gross IR:\", sharpe_ratio(active_gross))\n",
    "\n",
    "# ---- Plots (also saved to docs/assets for GitHub Pages) ----\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.plot(cum_port_gross, label=\"Strategy\")\n",
    "plt.plot(cum_bench, label=\"SPY\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative Returns: Strategy vs SPY\")\n",
    "fig.savefig(\"docs/assets/strategy_cumulative_returns.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "plt.plot(dd_port_gross, label=\"Strategy DD\")\n",
    "plt.plot(dd_bench, label=\"SPY DD\")\n",
    "plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "plt.legend()\n",
    "plt.title(\"Drawdowns: Strategy vs SPY\")\n",
    "fig.savefig(\"docs/assets/strategy_drawdowns.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Rolling 12-month total returns\n",
    "roll_12m_strategy = (1 + portfolio_returns).rolling(12).apply(np.prod, raw=True) - 1\n",
    "roll_12m_spy = (1 + benchmark_ret).rolling(12).apply(np.prod, raw=True) - 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "plt.plot(roll_12m_strategy, label=\"Strategy 12M\")\n",
    "plt.plot(roll_12m_spy, label=\"SPY 12M\")\n",
    "plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "plt.legend()\n",
    "plt.title(\"Rolling 12-Month Returns\")\n",
    "fig.savefig(\"docs/assets/strategy_rolling_12m_returns.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ce3e4",
   "metadata": {},
   "source": [
    "### 13A. Prototype Diagnostics (Data Health + Cost Sensitivity + Subperiods)\n",
    "\n",
    "This section summarizes data coverage, shows baseline performance sensitivity to simple turnover-based transaction cost assumptions, and reports subperiod performance to make regime dependence explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc8315",
   "metadata": {},
   "outputs": [],
   "source": [
    "_realized = df_total.set_index(\"date\")[tickers]\n",
    "missing_by_ticker = _realized.isna().mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"=== DATA HEALTH SUMMARY ===\")\n",
    "print(\"Tickers in merged dataset:\", len(tickers))\n",
    "print(\"Months in merged dataset:\", df_total[\"date\"].nunique())\n",
    "print(\"Overall missing return fraction (mean across tickers):\", float(missing_by_ticker.mean()))\n",
    "\n",
    "print(\"\\nTop 10 tickers by missing return fraction:\")\n",
    "display(missing_by_ticker.head(10).to_frame(\"missing_frac\"))\n",
    "\n",
    "eligible_universe = _realized.notna().sum(axis=1)\n",
    "print(\"\\nEligible universe size by month (min/avg/max):\",\n",
    "      int(eligible_universe.min()), float(eligible_universe.mean()), int(eligible_universe.max()))\n",
    "\n",
    "pred_coverage = pred_df.notna().sum(axis=1)\n",
    "print(\"Prediction coverage by month (min/avg/max):\",\n",
    "      int(pred_coverage.min()), float(pred_coverage.mean()), int(pred_coverage.max()))\n",
    "\n",
    "\n",
    "def _metrics_for_returns(r: pd.Series, rf: pd.Series):\n",
    "    r = pd.Series(r).dropna()\n",
    "    if len(r) == 0:\n",
    "        return {\n",
    "            \"Sharpe (Excess)\": np.nan,\n",
    "            \"CAGR\": np.nan,\n",
    "            \"Vol (ann.)\": np.nan,\n",
    "            \"Max DD\": np.nan,\n",
    "            \"Months\": 0,\n",
    "        }\n",
    "\n",
    "    rf_al = pd.Series(rf).reindex(r.index)\n",
    "    ex = r - rf_al\n",
    "    cum = (1 + r).cumprod()\n",
    "\n",
    "    return {\n",
    "        \"Sharpe (Excess)\": sharpe_ratio(ex),\n",
    "        \"CAGR\": cagr(r),\n",
    "        \"Vol (ann.)\": annualized_vol(r),\n",
    "        \"Max DD\": max_drawdown(cum),\n",
    "        \"Months\": len(r),\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"\\n=== TRANSACTION COST SENSITIVITY (BASELINE) ===\")\n",
    "cost_grid_bps = [0, 10, 25]\n",
    "rows = []\n",
    "for bps in cost_grid_bps:\n",
    "    net = portfolio_returns - (bps / 10000.0) * turnover\n",
    "    m = _metrics_for_returns(net, rf_series)\n",
    "    m[\"cost_bps\"] = bps\n",
    "    rows.append(m)\n",
    "\n",
    "cost_sens = pd.DataFrame(rows).set_index(\"cost_bps\")\n",
    "display(cost_sens)\n",
    "\n",
    "\n",
    "print(\"\\n=== SUBPERIOD PERFORMANCE (GROSS) ===\")\n",
    "subperiods = {\n",
    "    \"2011-2016\": (\"2011-01-01\", \"2016-12-31\"),\n",
    "    \"2017-2019\": (\"2017-01-01\", \"2019-12-31\"),\n",
    "    \"2020-2025\": (\"2020-01-01\", str(portfolio_returns.index.max().date())),\n",
    "}\n",
    "\n",
    "model_map = {\n",
    "    \"Strategy\": portfolio_returns,\n",
    "    \"SPY\": benchmark_ret,\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for period, (start, end) in subperiods.items():\n",
    "    for name, series in model_map.items():\n",
    "        r = pd.Series(series).loc[start:end]\n",
    "        rf_al = rf_series.reindex(r.index)\n",
    "        m = _metrics_for_returns(r, rf_al)\n",
    "        m[\"Model\"] = name\n",
    "        m[\"Period\"] = period\n",
    "        m[\"Start\"] = r.index.min().date() if len(r) else None\n",
    "        m[\"End\"] = r.index.max().date() if len(r) else None\n",
    "        rows.append(m)\n",
    "\n",
    "sub_tbl = pd.DataFrame(rows).set_index([\"Period\", \"Model\"])\n",
    "display(sub_tbl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f53080",
   "metadata": {},
   "source": [
    "## Part III. Two-Model ML Comparison (Linear vs XGBoost)\n",
    "\n",
    "After establishing the baseline factor strategy, we test **two machine learning models** for cross-sectional top‑50 selection using the same feature set (rolling FF5 betas) and the same walk-forward rules.\n",
    "\n",
    "- **Model 1 (Linear):** Logistic Regression classifier (linear decision boundary)\n",
    "- **Model 2 (XGBoost):** Learning-to-rank (non-linear interactions)\n",
    "\n",
    "**Project narrative:** we tried both ML models and selected the better-performing one based on out-of-sample backtest results (risk-adjusted metrics and robustness checks).\n",
    "\n",
    "### 13B. Model 2: XGBoost Learning-to-Rank (Top-K Stock Selection)\n",
    "\n",
    "**Key risks:** overfitting and look-ahead leakage.\n",
    "\n",
    "**How we avoid look-ahead bias here:**\n",
    "\n",
    "- Train uses only **past months**.\n",
    "- Features for month `t` use only information available through **`t-1`**.\n",
    "- Samples are grouped by month so the model learns **cross-sectional** ranking within each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost learning-to-rank (Top-K) — configuration\n",
    "\n",
    "# XGBRanker uses the scikit-learn API. If scikit-learn is missing, XGBRanker will error.\n",
    "try:\n",
    "    import sklearn  # noqa: F401\n",
    "    _HAS_SKLEARN = True\n",
    "except Exception:\n",
    "    _HAS_SKLEARN = False\n",
    "\n",
    "if not _HAS_XGBOOST:\n",
    "    _RUN_XGB = False\n",
    "    print(\"XGBoost is not installed. To run Model 2, install it with: pip install xgboost==2.0.3\")\n",
    "elif not _HAS_SKLEARN:\n",
    "    _RUN_XGB = False\n",
    "    print(\"scikit-learn is required for Model 2 (XGBRanker). Install it with: pip install scikit-learn==1.4.2\")\n",
    "else:\n",
    "    _RUN_XGB = True\n",
    "\n",
    "# Keep this section walk-forward only (no look-ahead)\n",
    "xgb_k = 50\n",
    "xgb_n_bins = 5\n",
    "xgb_min_train_months = 36\n",
    "xgb_train_window = 60\n",
    "xgb_retrain_every = 3  # train quarterly to reduce runtime; set to 1 to retrain monthly\n",
    "\n",
    "xgb_model_params = dict(\n",
    "    objective=\"rank:pairwise\",\n",
    "    n_estimators=120,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\",\n",
    "    verbosity=0,\n",
    ")\n",
    "\n",
    "# Placeholders so later cells won't crash if XGBoost isn't available\n",
    "panel_xgb = None\n",
    "xgb_feature_cols = None\n",
    "weights_xgb = None\n",
    "portfolio_returns_xgb = None\n",
    "portfolio_returns_xgb_net = None\n",
    "turnover_xgb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b62cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the feature/label panel used by the ML models (XGB ranker + Linear classifier)\n",
    "# Feature consistency: BOTH models use ONLY the 5 rolling FF5 betas: [MKT, SMB, HML, RMW, CMA]\n",
    "\n",
    "if _RUN_XGB:\n",
    "    realized = df_total.set_index(\"date\")[tickers]\n",
    "\n",
    "    def _stack_to_long(df_wide, value_name):\n",
    "        s = df_wide.stack(dropna=False).rename(value_name)\n",
    "        s.index = s.index.set_names([\"date\", \"ticker\"])\n",
    "        return s.reset_index()\n",
    "\n",
    "    # Betas in long form (betas at date t are estimated using months < t)\n",
    "    beta_long_parts = []\n",
    "    for tkr, bdf in beta_dict.items():\n",
    "        if bdf is None or bdf.empty:\n",
    "            continue\n",
    "        tmp = bdf[[\"MKT\", \"SMB\", \"HML\", \"RMW\", \"CMA\"]].copy()\n",
    "        tmp[\"ticker\"] = tkr\n",
    "        tmp[\"date\"] = pd.to_datetime(tmp.index)\n",
    "        beta_long_parts.append(tmp.reset_index(drop=True))\n",
    "\n",
    "    beta_long = pd.concat(beta_long_parts, ignore_index=True)\n",
    "\n",
    "    # Label: excess return in month t (y - RF)\n",
    "    rf = df_total.set_index(\"date\")[\"RF\"]\n",
    "    y_excess_wide = realized.sub(rf, axis=0)\n",
    "    y_excess_long = _stack_to_long(y_excess_wide, \"y_excess\")\n",
    "\n",
    "    # Shared panel (one row per date, ticker)\n",
    "    panel_ml = beta_long.merge(y_excess_long, on=[\"date\", \"ticker\"], how=\"left\")\n",
    "\n",
    "    xgb_feature_cols = [\"MKT\", \"SMB\", \"HML\", \"RMW\", \"CMA\"]\n",
    "\n",
    "    panel_ml = panel_ml.replace([np.inf, -np.inf], np.nan)\n",
    "    panel_ml = panel_ml.dropna(subset=xgb_feature_cols + [\"y_excess\"]).sort_values([\"date\", \"ticker\"]).reset_index(drop=True)\n",
    "\n",
    "    # Classification label (Linear model): 1 if excess return > 0 else 0\n",
    "    panel_ml[\"y_cls\"] = (panel_ml[\"y_excess\"] > 0).astype(int)\n",
    "\n",
    "    # Ranking label (XGBRanker): reserve rel=0 for non-positive excess, bin positives into 1..(B-1)\n",
    "    panel_xgb = panel_ml.copy()\n",
    "    B = xgb_n_bins\n",
    "    is_pos = panel_xgb[\"y_excess\"] > 0\n",
    "    panel_xgb[\"rel\"] = 0\n",
    "\n",
    "    pct = panel_xgb.loc[is_pos].groupby(\"date\")[\"y_excess\"].rank(pct=True, method=\"first\")\n",
    "    panel_xgb.loc[is_pos, \"rel\"] = (1 + np.floor(pct * (B - 1)).clip(0, B - 2)).astype(int)\n",
    "\n",
    "    print(\"panel_ml shape:\", panel_ml.shape)\n",
    "    print(\"panel_ml months:\", panel_ml[\"date\"].nunique())\n",
    "    print(\"panel_ml tickers (avg per month):\", panel_ml.groupby(\"date\").size().mean())\n",
    "    panel_ml.head()\n",
    "else:\n",
    "    print(\"Skipping panel build (XGBoost / scikit-learn not available).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f24015",
   "metadata": {},
   "source": [
    "#### 13B.2 Walk-forward training + monthly top-K selection\n",
    "\n",
    "We train the ranker on a rolling window of past months and then score/rank stocks for the next month.\n",
    "\n",
    "- Training uses **only months strictly before the test month**.\n",
    "- Each month is treated as one \"query group\" for learning-to-rank.\n",
    "- The output is a dictionary of monthly top-K selections, which we convert into equal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd39913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward Linear classifier (Logistic Regression) using ONLY the same 5 beta features\n",
    "\n",
    "try:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    _HAS_LOGREG = True\n",
    "except Exception:\n",
    "    LogisticRegression = None\n",
    "    _HAS_LOGREG = False\n",
    "\n",
    "lin_k = 50\n",
    "lin_min_train_months = 36\n",
    "lin_train_window = 60\n",
    "lin_retrain_every = 3\n",
    "\n",
    "weights_lin = None\n",
    "portfolio_returns_lin = None\n",
    "\n",
    "if _RUN_XGB and _HAS_LOGREG and (panel_ml is not None):\n",
    "    unique_dates = np.array(sorted(panel_ml[\"date\"].unique()))\n",
    "\n",
    "    lin_selected = {}\n",
    "    last_model = None\n",
    "    last_train_end = None\n",
    "\n",
    "    for i in range(len(unique_dates)):\n",
    "        dt = unique_dates[i]\n",
    "\n",
    "        train_end = i  # strictly before dt\n",
    "        train_start = max(0, train_end - lin_train_window)\n",
    "        train_dates = unique_dates[train_start:train_end]\n",
    "\n",
    "        if len(train_dates) < lin_min_train_months:\n",
    "            continue\n",
    "\n",
    "        train_df = panel_ml[panel_ml[\"date\"].isin(train_dates)].copy().sort_values([\"date\", \"ticker\"])\n",
    "        test_df = panel_ml[panel_ml[\"date\"] == dt].copy().sort_values([\"date\", \"ticker\"])\n",
    "\n",
    "        if len(test_df) == 0:\n",
    "            continue\n",
    "\n",
    "        need_retrain = (\n",
    "            last_model is None\n",
    "            or last_train_end is None\n",
    "            or lin_retrain_every == 1\n",
    "            or ((train_end - last_train_end) >= lin_retrain_every)\n",
    "        )\n",
    "\n",
    "        if need_retrain:\n",
    "            X_train = train_df[xgb_feature_cols].values\n",
    "            y_train = train_df[\"y_cls\"].values\n",
    "\n",
    "            clf = LogisticRegression(\n",
    "                penalty=\"l2\",\n",
    "                C=1.0,\n",
    "                solver=\"lbfgs\",\n",
    "                max_iter=1000,\n",
    "            )\n",
    "            clf.fit(X_train, y_train)\n",
    "            last_model = clf\n",
    "            last_train_end = train_end\n",
    "\n",
    "        X_test = test_df[xgb_feature_cols].values\n",
    "        p_good = last_model.predict_proba(X_test)[:, 1]  # P(y_excess > 0)\n",
    "\n",
    "        test_df = test_df.assign(p_good=p_good)\n",
    "        top = test_df.nlargest(min(lin_k, len(test_df)), \"p_good\")[\"ticker\"].tolist()\n",
    "        lin_selected[pd.to_datetime(dt)] = top\n",
    "\n",
    "    # Convert selections to equal weights\n",
    "    lin_dates = sorted(lin_selected.keys())\n",
    "    weights_lin = pd.DataFrame(0.0, index=pd.to_datetime(lin_dates), columns=tickers)\n",
    "\n",
    "    for dt, names in lin_selected.items():\n",
    "        if len(names) == 0:\n",
    "            continue\n",
    "        weights_lin.loc[dt, names] = 1.0 / len(names)\n",
    "\n",
    "    # Compute realized portfolio returns (same method as baseline)\n",
    "    realized_returns_lin = df_total.set_index(\"date\")[tickers]\n",
    "    common_index = weights_lin.index.intersection(realized_returns_lin.index)\n",
    "\n",
    "    weights_lin = weights_lin.loc[common_index]\n",
    "    realized_lin = realized_returns_lin.loc[common_index]\n",
    "\n",
    "    available = realized_lin.notna()\n",
    "    w_eff = weights_lin.where(available, 0.0)\n",
    "    denom = w_eff.sum(axis=1).replace(0.0, np.nan)\n",
    "\n",
    "    portfolio_returns_lin = (w_eff * realized_lin.fillna(0.0)).sum(axis=1) / denom\n",
    "    portfolio_returns_lin = portfolio_returns_lin.loc[denom.notna()]\n",
    "\n",
    "    print(\"Linear months:\", len(portfolio_returns_lin))\n",
    "    print(\"Linear start:\", portfolio_returns_lin.index.min().date())\n",
    "    print(\"Linear end:  \", portfolio_returns_lin.index.max().date())\n",
    "else:\n",
    "    print(\"Skipping linear classifier (requires scikit-learn + panel_ml).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward training and portfolio construction\n",
    "\n",
    "if _RUN_XGB:\n",
    "    unique_dates = np.array(sorted(panel_xgb[\"date\"].unique()))\n",
    "\n",
    "    xgb_selected = {}\n",
    "    last_model = None\n",
    "    last_train_end = None\n",
    "\n",
    "    for i in range(len(unique_dates)):\n",
    "        dt = unique_dates[i]\n",
    "\n",
    "        train_end = i  # strictly before dt\n",
    "        train_start = max(0, train_end - xgb_train_window)\n",
    "        train_dates = unique_dates[train_start:train_end]\n",
    "\n",
    "        if len(train_dates) < xgb_min_train_months:\n",
    "            continue\n",
    "\n",
    "        train_df = panel_xgb[panel_xgb[\"date\"].isin(train_dates)].copy().sort_values([\"date\", \"ticker\"])\n",
    "        test_df = panel_xgb[panel_xgb[\"date\"] == dt].copy().sort_values([\"date\", \"ticker\"])\n",
    "\n",
    "        if len(test_df) == 0:\n",
    "            continue\n",
    "\n",
    "        need_retrain = (\n",
    "            last_model is None\n",
    "            or last_train_end is None\n",
    "            or xgb_retrain_every == 1\n",
    "            or ((train_end - last_train_end) >= xgb_retrain_every)\n",
    "        )\n",
    "\n",
    "        if need_retrain:\n",
    "            grp = train_df.groupby(\"date\").size().values\n",
    "            X_train = train_df[xgb_feature_cols].values\n",
    "            y_train = train_df[\"rel\"].values\n",
    "\n",
    "            ranker = XGBRanker(\n",
    "                **xgb_model_params,\n",
    "                eval_metric=f\"ndcg@{xgb_k}\",\n",
    "            )\n",
    "\n",
    "            ranker.fit(X_train, y_train, group=grp)\n",
    "            last_model = ranker\n",
    "            last_train_end = train_end\n",
    "\n",
    "        X_test = test_df[xgb_feature_cols].values\n",
    "        scores = last_model.predict(X_test)\n",
    "\n",
    "        test_df = test_df.assign(score=scores)\n",
    "        top = test_df.nlargest(min(xgb_k, len(test_df)), \"score\")[\"ticker\"].tolist()\n",
    "        xgb_selected[pd.to_datetime(dt)] = top\n",
    "\n",
    "    # Convert selections to equal weights\n",
    "    xgb_dates = sorted(xgb_selected.keys())\n",
    "    weights_xgb = pd.DataFrame(0.0, index=pd.to_datetime(xgb_dates), columns=tickers)\n",
    "\n",
    "    for dt, names in xgb_selected.items():\n",
    "        if len(names) == 0:\n",
    "            continue\n",
    "        weights_xgb.loc[dt, names] = 1.0 / len(names)\n",
    "\n",
    "    # Compute realized portfolio returns (same method as baseline)\n",
    "    realized_returns_xgb = df_total.set_index(\"date\")[tickers]\n",
    "    common_index = weights_xgb.index.intersection(realized_returns_xgb.index)\n",
    "\n",
    "    weights_xgb = weights_xgb.loc[common_index]\n",
    "    realized_xgb = realized_returns_xgb.loc[common_index]\n",
    "\n",
    "    available = realized_xgb.notna()\n",
    "    w_eff = weights_xgb.where(available, 0.0)\n",
    "    denom = w_eff.sum(axis=1).replace(0.0, np.nan)\n",
    "\n",
    "    weights_used_xgb = w_eff.div(denom, axis=0)\n",
    "    portfolio_returns_xgb = (w_eff * realized_xgb.fillna(0.0)).sum(axis=1) / denom\n",
    "\n",
    "    active = denom.notna()\n",
    "    portfolio_returns_xgb = portfolio_returns_xgb.loc[active]\n",
    "    weights_used_xgb = weights_used_xgb.loc[active]\n",
    "\n",
    "    turnover_xgb = 0.5 * weights_used_xgb.diff().abs().sum(axis=1).fillna(0.0)\n",
    "    portfolio_returns_xgb_net = portfolio_returns_xgb - cost_rate * turnover_xgb\n",
    "\n",
    "    print(\"XGB months:\", len(portfolio_returns_xgb))\n",
    "    print(\"XGB start:\", portfolio_returns_xgb.index.min().date())\n",
    "    print(\"XGB end:  \", portfolio_returns_xgb.index.max().date())\n",
    "else:\n",
    "    print(\"Skipping walk-forward training/backtest (XGBoost / scikit-learn not available).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a9a50",
   "metadata": {},
   "source": [
    "#### 13B.3 Model Comparison (Model 1: Linear vs Model 2: XGBoost vs SPY)\n",
    "\n",
    "For a fair comparison we align all series to the **same XGB backtest window** and compute:\n",
    "- Sharpe ratio on excess returns\n",
    "- CAGR on total returns\n",
    "- A cumulative return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe60c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison report (aligned to XGB window)\n",
    "\n",
    "if _RUN_XGB and portfolio_returns_xgb is not None and len(portfolio_returns_xgb) > 0:\n",
    "    aligned_idx = portfolio_returns_xgb.index\n",
    "\n",
    "    bench_xgb = benchmark.reindex(aligned_idx)\n",
    "    rf_xgb = df_total.set_index(\"date\")[\"RF\"].reindex(aligned_idx)\n",
    "\n",
    "    # XGB excess\n",
    "    xgb_excess = portfolio_returns_xgb - rf_xgb\n",
    "\n",
    "    # SPY excess\n",
    "    bench_excess_xgb = bench_xgb - rf_xgb\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 78)\n",
    "    print(\"MODEL COMPARISON (ALIGNED TO XGB WINDOW)\")\n",
    "    print(\"=\" * 78)\n",
    "\n",
    "    if portfolio_returns_lin is not None and len(portfolio_returns_lin.dropna()) > 0:\n",
    "        lin_al = portfolio_returns_lin.reindex(aligned_idx)\n",
    "        lin_excess = lin_al - rf_xgb\n",
    "\n",
    "        print(\"\\nSharpe (Excess Returns):\")\n",
    "        print(\"  Linear: \", sharpe_ratio(lin_excess))\n",
    "        print(\"  XGB:    \", sharpe_ratio(xgb_excess))\n",
    "        print(\"  SPY:    \", sharpe_ratio(bench_excess_xgb))\n",
    "\n",
    "        print(\"\\nCAGR (Total Returns):\")\n",
    "        print(\"  Linear: \", cagr(lin_al))\n",
    "        print(\"  XGB:    \", cagr(portfolio_returns_xgb))\n",
    "        print(\"  SPY:    \", cagr(bench_xgb))\n",
    "\n",
    "        cum_lin = (1 + lin_al.fillna(0.0)).cumprod()\n",
    "        cum_xgb = (1 + portfolio_returns_xgb.fillna(0.0)).cumprod()\n",
    "        cum_spy = (1 + bench_xgb.fillna(0.0)).cumprod()\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 5))\n",
    "        plt.plot(cum_lin, label=\"Linear\")\n",
    "        plt.plot(cum_xgb, label=\"XGB Ranker\")\n",
    "        plt.plot(cum_spy, label=\"SPY\")\n",
    "        plt.title(\"Cumulative Returns: Linear vs XGBoost Ranker vs SPY\")\n",
    "        plt.legend()\n",
    "        fig.savefig(\"docs/assets/strategy_cumulative_returns_xgb_compare.png\", dpi=200, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nLinear backtest not available; showing XGB vs SPY only.\")\n",
    "\n",
    "        print(\"\\nSharpe (Excess Returns):\")\n",
    "        print(\"  XGB: \", sharpe_ratio(xgb_excess))\n",
    "        print(\"  SPY: \", sharpe_ratio(bench_excess_xgb))\n",
    "\n",
    "        print(\"\\nCAGR (Total Returns):\")\n",
    "        print(\"  XGB: \", cagr(portfolio_returns_xgb))\n",
    "        print(\"  SPY: \", cagr(bench_xgb))\n",
    "\n",
    "        cum_xgb = (1 + portfolio_returns_xgb.fillna(0.0)).cumprod()\n",
    "        cum_spy = (1 + bench_xgb.fillna(0.0)).cumprod()\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 5))\n",
    "        plt.plot(cum_xgb, label=\"XGB Ranker\")\n",
    "        plt.plot(cum_spy, label=\"SPY\")\n",
    "        plt.title(\"Cumulative Returns: XGBoost Ranker vs SPY\")\n",
    "        plt.legend()\n",
    "        fig.savefig(\"docs/assets/strategy_cumulative_returns_xgb_compare.png\", dpi=200, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Skipping comparison (XGBoost backtest not available).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c08cae6",
   "metadata": {},
   "source": [
    "### 14. Final Comparison: Two ML Models (Linear vs XGBoost) vs SPY\n",
    "\n",
    "#### Transaction costs (what they were, and why we disabled them)\n",
    "\n",
    "Earlier, **net returns** were computed by subtracting a simple turnover-based transaction cost:\n",
    "\n",
    "\\[\n",
    "R^{net}_t = R^{gross}_t - (\\text{cost\\_rate} \\times \\text{turnover}_t)\n",
    "\\]\n",
    "\n",
    "where turnover is computed from changes in portfolio weights.\n",
    "\n",
    "**For your submission, transaction costs are now set to 0 bps (disabled)** so that all results are purely **gross** and easier to interpret.\n",
    "\n",
    "(If you ever want to re-enable costs, set `cost_bps` to a positive value in the performance cell.)\n",
    "\n",
    "#### What this section produces\n",
    "\n",
    "We compare on a **common aligned window**:\n",
    "- Summary metrics table\n",
    "- Calendar-year return table\n",
    "- Simple comparison plots for:\n",
    "  - Cumulative returns\n",
    "  - Drawdowns\n",
    "  - Rolling 12-month returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66819e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All-model comparison tables + simple plots (aligned window)\n",
    "\n",
    "def _perf_summary_table(model_returns, rf):\n",
    "    rows = []\n",
    "    for name, r in model_returns.items():\n",
    "        r = pd.Series(r).dropna()\n",
    "        if len(r) == 0:\n",
    "            continue\n",
    "\n",
    "        rf_al = rf.reindex(r.index)\n",
    "        ex = r - rf_al\n",
    "\n",
    "        cum = (1 + r).cumprod()\n",
    "        mdd = max_drawdown(cum)\n",
    "        c = cagr(r)\n",
    "        vol = annualized_vol(r)\n",
    "        shrp = sharpe_ratio(ex)\n",
    "        calmar = c / abs(mdd) if pd.notna(mdd) and mdd != 0 else np.nan\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Model\": name,\n",
    "                \"Start\": r.index.min().date(),\n",
    "                \"End\": r.index.max().date(),\n",
    "                \"Months\": len(r),\n",
    "                \"Sharpe (Excess)\": shrp,\n",
    "                \"CAGR\": c,\n",
    "                \"Vol (ann.)\": vol,\n",
    "                \"Max DD\": mdd,\n",
    "                \"Calmar\": calmar,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    out = pd.DataFrame(rows).set_index(\"Model\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def _calendar_year_returns(r):\n",
    "    r = pd.Series(r).dropna()\n",
    "    if len(r) == 0:\n",
    "        return pd.Series(dtype=float)\n",
    "    by_year = (1 + r).groupby(r.index.year).prod() - 1\n",
    "    return by_year\n",
    "\n",
    "\n",
    "# Determine common window for comparison (SPY vs Linear vs XGB)\n",
    "model_series = {\n",
    "    \"SPY\": benchmark_ret,\n",
    "}\n",
    "\n",
    "if portfolio_returns_lin is not None:\n",
    "    model_series[\"Linear\"] = portfolio_returns_lin\n",
    "if portfolio_returns_xgb is not None:\n",
    "    model_series[\"XGB\"] = portfolio_returns_xgb\n",
    "\n",
    "common_idx = None\n",
    "for s in model_series.values():\n",
    "    idx = pd.Series(s).dropna().index\n",
    "    common_idx = idx if common_idx is None else common_idx.intersection(idx)\n",
    "\n",
    "common_idx = common_idx.sort_values()\n",
    "\n",
    "if len(common_idx) == 0:\n",
    "    print(\"No overlapping dates across models; cannot compare.\")\n",
    "else:\n",
    "    aligned_models = {k: pd.Series(v).reindex(common_idx) for k, v in model_series.items()}\n",
    "    rf_common = df_total.set_index(\"date\")[\"RF\"].reindex(common_idx)\n",
    "\n",
    "    # Summary table\n",
    "    summary = _perf_summary_table(aligned_models, rf_common)\n",
    "    summary_fmt = summary.copy()\n",
    "\n",
    "    for col in [\"Sharpe (Excess)\", \"CAGR\", \"Vol (ann.)\", \"Max DD\", \"Calmar\"]:\n",
    "        if col in [\"Sharpe (Excess)\", \"Calmar\"]:\n",
    "            summary_fmt[col] = summary_fmt[col].map(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"\")\n",
    "        else:\n",
    "            summary_fmt[col] = summary_fmt[col].map(lambda x: f\"{x:.2%}\" if pd.notna(x) else \"\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 78)\n",
    "    print(\"MODEL SUMMARY (ALIGNED WINDOW)\")\n",
    "    print(\"=\" * 78)\n",
    "    print(f\"Common start: {common_idx.min().date()}  |  Common end: {common_idx.max().date()}  |  Months: {len(common_idx)}\")\n",
    "    display(summary_fmt)\n",
    "\n",
    "    yr = pd.DataFrame({name: _calendar_year_returns(r) for name, r in aligned_models.items()}).sort_index()\n",
    "    yr_fmt = yr.applymap(lambda x: f\"{x:.2%}\" if pd.notna(x) else \"\")\n",
    "\n",
    "    print(\"\\nCalendar-year returns (aligned window):\")\n",
    "    display(yr_fmt)\n",
    "\n",
    "    # ---- Simple comparison plots (3 total) ----\n",
    "    plot_df = pd.DataFrame(aligned_models).fillna(0.0)\n",
    "\n",
    "    # Cumulative returns\n",
    "    cum = (1 + plot_df).cumprod()\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    for col in cum.columns:\n",
    "        plt.plot(cum.index, cum[col], label=col)\n",
    "    plt.title(\"Cumulative Returns (Aligned): SPY vs Linear vs XGB\")\n",
    "    plt.legend()\n",
    "    fig.savefig(\"docs/assets/compare_cumulative.png\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Drawdowns\n",
    "    dd = cum / cum.cummax() - 1\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    for col in dd.columns:\n",
    "        plt.plot(dd.index, dd[col], label=col)\n",
    "    plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "    plt.title(\"Drawdowns (Aligned): SPY vs Linear vs XGB\")\n",
    "    plt.legend()\n",
    "    fig.savefig(\"docs/assets/compare_drawdowns.png\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Rolling 12-month returns\n",
    "    roll_12m = (1 + plot_df).rolling(12).apply(np.prod, raw=True) - 1\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    for col in roll_12m.columns:\n",
    "        plt.plot(roll_12m.index, roll_12m[col], label=col)\n",
    "    plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "    plt.title(\"Rolling 12-Month Returns (Aligned): SPY vs Linear vs XGB\")\n",
    "    plt.legend()\n",
    "    fig.savefig(\"docs/assets/compare_rolling_12m.png\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d2e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verification & sanity checks (plain) ---\n",
    "# Not used to build the strategy; only sanity-check results and guard against look-ahead bias.\n",
    "\n",
    "\n",
    "def _fmt_pct(x, decimals=2):\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return f\"{x * 100:.{decimals}f}%\"\n",
    "\n",
    "\n",
    "def calendar_year_returns(r):\n",
    "    r = pd.Series(r).dropna()\n",
    "    if len(r) == 0:\n",
    "        return pd.Series(dtype=float)\n",
    "    return (1 + r).groupby(r.index.year).prod() - 1\n",
    "\n",
    "\n",
    "def months_per_year(r):\n",
    "    r = pd.Series(r).dropna()\n",
    "    if len(r) == 0:\n",
    "        return pd.Series(dtype=int)\n",
    "    return r.groupby(r.index.year).size()\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 78)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\" * 78)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1) Calendar-year return verification (Strategy vs SPY)\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\" * 78)\n",
    "print(\"1) CALENDAR-YEAR RETURNS (Strategy vs SPY)\")\n",
    "print(\"-\" * 78)\n",
    "\n",
    "yr_strategy = calendar_year_returns(portfolio_returns)\n",
    "yr_spy = calendar_year_returns(benchmark_ret)\n",
    "\n",
    "annual = pd.DataFrame(\n",
    "    {\n",
    "        \"Months\": months_per_year(portfolio_returns),\n",
    "        \"Strategy\": yr_strategy,\n",
    "        \"SPY\": yr_spy,\n",
    "    }\n",
    ").sort_index()\n",
    "\n",
    "annual[\"Active\"] = annual[\"Strategy\"] - annual[\"SPY\"]\n",
    "\n",
    "annual_fmt = annual.copy()\n",
    "for col in [\"Strategy\", \"SPY\", \"Active\"]:\n",
    "    annual_fmt[col] = annual_fmt[col].map(_fmt_pct)\n",
    "\n",
    "print(annual_fmt)\n",
    "\n",
    "full_years = annual[annual[\"Months\"] == 12]\n",
    "\n",
    "print(\"\\nAverage yearly returns (all years, incl. partial):\")\n",
    "print(f\"  Strategy: {annual['Strategy'].mean():.4f}\")\n",
    "print(f\"  SPY:      {annual['SPY'].mean():.4f}\")\n",
    "\n",
    "if len(full_years) > 0:\n",
    "    print(\"\\nAverage yearly returns (FULL years only, 12 months):\")\n",
    "    print(f\"  Strategy: {full_years['Strategy'].mean():.4f}\")\n",
    "    print(f\"  SPY:      {full_years['SPY'].mean():.4f}\")\n",
    "else:\n",
    "    print(\"\\nAverage yearly returns (FULL years only): SKIPPED (no complete 12-month years)\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) Look-ahead bias sanity checks\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\" * 78)\n",
    "print(\"2) LOOK-AHEAD CHECKS\")\n",
    "print(\"-\" * 78)\n",
    "\n",
    "# A) Factor forecast lag test\n",
    "try:\n",
    "    if \"factor_hist\" not in globals() or \"factor_forecast\" not in globals():\n",
    "        raise RuntimeError(\"factor_hist / factor_forecast not found\")\n",
    "\n",
    "    nonnull = factor_forecast.dropna()\n",
    "    if len(nonnull) == 0:\n",
    "        raise RuntimeError(\"no non-null forecast months found\")\n",
    "\n",
    "    dt = nonnull.index[0]\n",
    "\n",
    "    manual_window = factor_hist.loc[:dt].iloc[:-1].tail(36)\n",
    "    manual_mean = manual_window.mean()\n",
    "    max_abs_diff = (manual_mean - factor_forecast.loc[dt]).abs().max()\n",
    "\n",
    "    if max_abs_diff < 1e-12:\n",
    "        print(f\"A) factor_forecast uses shift(1): PASS (checked {dt.date()})\")\n",
    "    else:\n",
    "        print(f\"A) factor_forecast uses shift(1): WARN (max abs diff = {max_abs_diff:.3e})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"A) factor_forecast lag test: SKIPPED ({e})\")\n",
    "\n",
    "# B) Rolling beta window test (manual recompute for one ticker and one date)\n",
    "try:\n",
    "    test_ticker = next((t for t, b in beta_dict.items() if b is not None and not b.empty), None)\n",
    "    if test_ticker is None:\n",
    "        raise RuntimeError(\"no ticker with computed betas found\")\n",
    "\n",
    "    betas = beta_dict[test_ticker]\n",
    "    test_dt = betas.index[0]\n",
    "\n",
    "    df_ex_idx = df_excess.set_index(\"date\")\n",
    "\n",
    "    pos_arr = df_ex_idx.index.get_indexer([pd.Timestamp(test_dt)])\n",
    "    pos = int(pos_arr[0]) if len(pos_arr) > 0 else -1\n",
    "    if pos < 0:\n",
    "        raise RuntimeError(f\"could not find beta date {pd.Timestamp(test_dt).date()} in df_excess index\")\n",
    "\n",
    "    window = 36\n",
    "    min_obs = 24\n",
    "    if pos < window:\n",
    "        raise RuntimeError(f\"insufficient history at first beta date (pos={pos}, window={window})\")\n",
    "\n",
    "    y_slice = df_ex_idx[test_ticker].astype(float).values[pos - window:pos]\n",
    "    X_slice = df_ex_idx[[\"Mkt-RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\"]].astype(float).values[pos - window:pos]\n",
    "    X_slice = np.column_stack([np.ones(len(X_slice)), X_slice])\n",
    "\n",
    "    mask = np.isfinite(y_slice) & np.all(np.isfinite(X_slice), axis=1)\n",
    "    if mask.sum() < min_obs:\n",
    "        raise RuntimeError(f\"not enough finite observations in window (have {mask.sum()}, need {min_obs})\")\n",
    "\n",
    "    beta_manual = ols_numpy(X_slice[mask], y_slice[mask])\n",
    "    beta_reported = betas.loc[test_dt, [\"alpha\", \"MKT\", \"SMB\", \"HML\", \"RMW\", \"CMA\"]].values\n",
    "\n",
    "    max_beta_diff = float(np.max(np.abs(beta_manual - beta_reported)))\n",
    "\n",
    "    if max_beta_diff < 1e-10:\n",
    "        print(f\"B) rolling betas exclude month t in fit: PASS (ticker {test_ticker}, {pd.Timestamp(test_dt).date()})\")\n",
    "    else:\n",
    "        print(f\"B) rolling beta window: WARN (max diff: {max_beta_diff:.3e})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"B) rolling beta window test: SKIPPED ({e})\")\n",
    "\n",
    "print(\"C) prediction signal excludes alpha: PASS\")\n",
    "print(\"\\nIf A is PASS and B is PASS (or SKIPPED with a clear reason), you’re consistent with no look-ahead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8415a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simple model summary box (SPY vs Linear vs XGB) ---\n",
    "\n",
    "# Ensure full column widths are displayed\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "def _max_dd_from_returns(r):\n",
    "    r = pd.Series(r).dropna()\n",
    "    if len(r) == 0:\n",
    "        return np.nan\n",
    "    cum = (1 + r).cumprod()\n",
    "    return (cum / cum.cummax() - 1).min()\n",
    "\n",
    "\n",
    "def _summary_row(name, r, rf=None, features=\"\", objective=\"\", selection=\"\"):\n",
    "    r = pd.Series(r).dropna()\n",
    "    if len(r) == 0:\n",
    "        return None\n",
    "\n",
    "    rf_al = rf.reindex(r.index) if rf is not None else pd.Series(index=r.index, data=0.0)\n",
    "    ex = r - rf_al\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Features\": features,\n",
    "        \"Objective/Label\": objective,\n",
    "        \"Portfolio Rule\": selection,\n",
    "        \"Start\": r.index.min().date(),\n",
    "        \"End\": r.index.max().date(),\n",
    "        \"Months\": len(r),\n",
    "        \"Sharpe\": sharpe_ratio(ex),\n",
    "        \"CAGR\": cagr(r),\n",
    "        \"Max DD\": _max_dd_from_returns(r),\n",
    "    }\n",
    "\n",
    "\n",
    "rf_series = df_total.set_index(\"date\")[\"RF\"]\n",
    "\n",
    "rows = []\n",
    "\n",
    "# SPY benchmark\n",
    "rows.append(\n",
    "    _summary_row(\n",
    "        name=\"SPY (Benchmark)\",\n",
    "        r=benchmark_ret,\n",
    "        rf=rf_series,\n",
    "        features=\"N/A\",\n",
    "        objective=\"Passive benchmark (S&P 500 ETF)\",\n",
    "        selection=\"Buy & Hold\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Linear classifier (Logistic Regression)\n",
    "if portfolio_returns_lin is not None:\n",
    "    rows.append(\n",
    "        _summary_row(\n",
    "            name=\"Linear (LogReg)\",\n",
    "            r=portfolio_returns_lin,\n",
    "            rf=rf_series,\n",
    "            features=\"5 rolling FF5 betas: MKT, SMB, HML, RMW, CMA\",\n",
    "            objective=\"Binary classification: P(y_excess > 0) via Logistic Regression\",\n",
    "            selection=\"Top-50 by predicted probability, equal weight\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# XGBoost ranker\n",
    "if portfolio_returns_xgb is not None:\n",
    "    rows.append(\n",
    "        _summary_row(\n",
    "            name=\"XGBRanker (pairwise)\",\n",
    "            r=portfolio_returns_xgb,\n",
    "            rf=rf_series,\n",
    "            features=\"5 rolling FF5 betas: MKT, SMB, HML, RMW, CMA\",\n",
    "            objective=\"Pairwise ranking: rel bins from y_excess; bin 0 for y_excess ≤ 0\",\n",
    "            selection=\"Top-50 by ranking score, equal weight\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "summary_box = pd.DataFrame([r for r in rows if r is not None]).set_index(\"Model\")\n",
    "\n",
    "# Pretty formatting for display\n",
    "summary_fmt = summary_box.copy()\n",
    "summary_fmt[\"Sharpe\"] = summary_fmt[\"Sharpe\"].map(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"\")\n",
    "summary_fmt[\"CAGR\"] = summary_fmt[\"CAGR\"].map(lambda x: f\"{x:.2%}\" if pd.notna(x) else \"\")\n",
    "summary_fmt[\"Max DD\"] = summary_fmt[\"Max DD\"].map(lambda x: f\"{x:.2%}\" if pd.notna(x) else \"\")\n",
    "\n",
    "display(summary_fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba44c52",
   "metadata": {},
   "source": [
    "### 14. Limitations (Important)\n",
    "\n",
    "- **Survivorship bias**: the universe is based on a current S&P 500 constituents list (not point-in-time membership), which likely biases backtest results upward.\n",
    "- **Data limitations**: monthly returns reduce noise but also hide intra-month dynamics; delistings and corporate actions may not be fully captured.\n",
    "- **Transaction costs**: modeled as a simple turnover-based bps cost; real-world costs depend on liquidity, spreads, and market impact.\n",
    "- **Forecasting**: factor forecasts are a simple rolling mean baseline; more sophisticated forecasts may perform differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inference (XGB only): recommend tickers for the latest available month ---\n",
    "\n",
    "infer_k = 50\n",
    "\n",
    "if not (_RUN_XGB and _HAS_XGBOOST) or panel_xgb is None or xgb_feature_cols is None:\n",
    "    raise ValueError(\"XGBoost not enabled or panel_xgb/xgb_feature_cols missing. Run the XGB section first.\")\n",
    "\n",
    "latest_dt = pd.to_datetime(sorted(panel_xgb[\"date\"].unique())[-1])\n",
    "train_dates = sorted([d for d in panel_xgb[\"date\"].unique() if pd.to_datetime(d) < latest_dt])\n",
    "\n",
    "print(\"Inference month:\", latest_dt.date())\n",
    "print(\"Train months:\", len(train_dates), \"| Train end:\", pd.to_datetime(train_dates[-1]).date())\n",
    "\n",
    "train_x = panel_xgb[panel_xgb[\"date\"].isin(train_dates)].copy().sort_values([\"date\", \"ticker\"])\n",
    "test_x  = panel_xgb[panel_xgb[\"date\"] == latest_dt].copy().sort_values([\"date\", \"ticker\"])\n",
    "\n",
    "group_train = train_x.groupby(\"date\").size().to_numpy()\n",
    "\n",
    "xgb_model = XGBRanker(**xgb_model_params)\n",
    "xgb_model.fit(\n",
    "    train_x[xgb_feature_cols].values,\n",
    "    train_x[\"rel\"].values,\n",
    "    group=group_train,\n",
    ")\n",
    "\n",
    "scores = xgb_model.predict(test_x[xgb_feature_cols].values)\n",
    "xgb_rank = test_x.assign(score=scores).sort_values(\"score\", ascending=False)\n",
    "\n",
    "xgb_top = xgb_rank.head(min(infer_k, len(xgb_rank)))[[\"ticker\", \"score\"]].reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTop tickers to invest in (XGBRanker score):\")\n",
    "display(xgb_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716dd9a9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
